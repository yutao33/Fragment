\section{理论推导}

本节给出ICA理论的具体数学推导，推导的过程主要参考了\cite{icachinese,ica,fastica,icatutorial}。

\subsection{问题定义}
可以使用统计上的“隐变量”模型定义ICA问题，假设观察到$n$个随机变量$x_1,x_2,\ldots,x_n$，而这些变量是由另外$n$个随机变量$s_1,s_2,\ldots,s_n$线性组合得到，可以用矩阵形式表示如下
\begin{equation}
    \mathbf{x}=\mathbf{As}
\end{equation}
其中
\begin{equation}
    \mathbf{x}=\left(
        \begin{aligned}
        x_1\\
        x_2\\
        \vdots\\
        x_n
        \end{aligned}
    \right),
    \mathbf{s}=\left(
        \begin{aligned}
        s_1\\
        s_2\\
        \vdots\\
        s_n
        \end{aligned}
    \right),
    \mathbf{A}=\left(
        \begin{array}{cccc}
        a_{11} & a_{12} & \cdots & a_{1n} \\ 
        a_{21} & a_{22} & \cdots & a_{2n} \\ 
        \vdots & \vdots & \ddots & \vdots \\ 
        a_{n1} & a_{n2} & \cdots & a_{nn}
        \end{array} 
    \right)
\end{equation}

\textbf{假设和约束}：为了确保ICA模型可以被估计，必须做出下面的假设和约束
\begin{enumerate}
    \item 假设独立成分是统计独立的
    \item 独立成分具有非高斯的分布
    \item 未知的混合矩阵是方阵
\end{enumerate}

\textbf{ICA中的不确定性}：在以上定义的ICA模型中，可以发现存在下面一些不确定性
\begin{enumerate}
    \item 无法确定独立成分的方差
    \item 无法确定独立成分的次序
\end{enumerate}

\textbf{变量的中心化}：不失一般性，我们可以假定所有的混合变量与独立成分均具有零均值。这作为下面推导的一个默认假设，如果实际情况不满足零均值假设，可以进行中心化的预处理：
\begin{equation} 
    \mathbf{x}=\mathbf{x'}-E{\mathbf{x'}}
\end{equation}
这样独立成分也同时变为零均值的量，因为：
\begin{equation}
    E{\mathbf{s}}=\mathbf{A}^{-1}E{\mathbf{x}}
\end{equation}

\textbf{不相关性和白化}：不相关性是独立性的一个弱化的形式。如果两个随机变量$y_1$和$y_2$的协方差为零，我们说这两个变量是不相关的：
\begin{equation}
    cov(y_1,y_2)=E\{y_1y_2\}-E\{y_1\}E\{y_2\}=0
\end{equation}
如果随机变量是相互独立的，那么他们就是不相关的，但是不相关并不意味着独立。

白化性(whiteness)是指一个零均值的随机向$y$的各个分量具有相同的单位方差且互相不相关，换句话说$y$的协方差矩阵是单位矩阵：
\begin{equation}
    E\{\textbf{yy}^T\}=\mathbf{\mathit{I}}
\end{equation}
白化意味着我们将观察得到的数据向量$\mathbf{x}$与某个矩阵$\mathbf{V}$相乘后得到的是一个新的白化的向量：
\begin{equation}
    \mathbf{z}=\mathbf{Vx}
\end{equation}
白化变换总是可实现的，一般可以利用协方差矩阵的特征值分解（EVD）:
\begin{equation}
    E\{\textbf{xx}^T \}=\textbf{EDE}^T
\end{equation}
式中，$\mathbf{E}$是$E\{\mathbf{xx}^T \}$的特征向量的正交矩阵，$\textbf{D}$是相应的特征向量的对角矩阵，$D=diag\{d_1,d_2,\cdots,d_n\}$。这样，白化过程可以利用下面的白化矩阵来实现：
\begin{equation}
    \mathbf{V}=\mathbf{E}\mathbf{D}^{-1/2}\mathbf{E}^T
\end{equation}
式中，矩阵$\mathbf{D}^{-1/2}=diag\{d_1^{-1/2},d_2^{-1/2},\cdots,d_n^{-1/2}\}$。这样得到的白化矩阵记为$E\{\mathbf{xx}^T\}^{-1/2}$或$\mathbf{C}^{-1/2}$。在后文的推导过程中，对数据的白化处理也是很重要的一个环节。


\subsection{极大化非高斯性的ICA估计方法}

\textbf{关于非高斯性}：如果两个独立成分$s_1$和$s_2$是高斯分布的，则它们的联合概率密度可以表示为：
\begin{equation}
p(s_1,s_2)
=\frac{1}{2\pi}exp(-\frac{s_1^2+s_2^2}{2})
=\frac{1}{2\pi}exp(-\frac{{\lVert \mathbf{s} \rVert}^2}{2})
\end{equation}
假定混合矩阵是正交的。根据概率密度函数的变换公式（参见附录\ref{apx:1}）,根据正交矩阵的特点，$\textbf{A}^{-1}=\textbf{A}^T$成立，可以得到混合变量$x_1$和$x_2$的联合密度函数为：
\begin{equation}
p(x_1,x_2)
=\frac{1}{2\pi}exp(-\frac{{\lVert \mathbf{A}^T\mathbf{x} \rVert}^2}{2})|\text{det}\,\mathbf{A}^T|    
\end{equation}
由$\mathbf{A}$的正交性可知${\lVert \mathbf{A}^T\mathbf{x} \rVert}^2={\lVert \mathbf{x} \rVert}^2$和$|\text{det}\,\mathbf{A}|=1$成立。另外如果$\textbf{A}$是正交的，其转置$\textbf{A}^T$也同样是正交的。因此我们有：
\begin{equation}
p(x_1,x_2)
=\frac{1}{2\pi}exp(-\frac{{\lVert \mathbf{x} \rVert}^2}{2})
\end{equation}
这里可以看出混合变量的概率密度函数和原始的概率密度函数都是二维高斯分布，我们没有任何办法得到混合矩阵的信息。

\textbf{极大化非高斯性的原理}：中心极限定理是概率论中的一个经典结论，该定理告诉我们，独立的随机变量之和的分布趋向于高斯分布。或者不那么严格的讲，可以认为两个独立随机变量之和形成的分布比两个原始的随机变量中的任意一个更接近于高斯分布。

现在为了估计出ICA数据模型中的一个独立成分，我们先假定所有独立成分具有相同的分布，可以考虑对$x_i$进行某种线性组合，有：
\begin{equation}
    y=\mathbf{b}^T\mathbf{x}=\mathbf{q}^T\mathbf{s}=\sum_{i}q_is_i
\end{equation}
如果$\mathbf{b}$是$\mathbf{A}^{-1}$中的一行，那么该线性组合$\mathbf{b}^T\mathbf{A}$就等于其中一个独立成分，而对应的向量$\mathbf{q}$只有一个元素为1，其他的元素均为0.

问题在于：我们如何使用中心极限定理确定$\mathbf{b}$，是的它刚好等于$\mathbf{A}$的逆矩阵中的一行？实际上，我们无法准确地得到这样地$\mathbf{b}$,因为没有关于矩阵$\mathbf{A}$的先验知识，但是可以找到具有较好近似程度的一个估计。

我们可以通过改变$\mathbf{q}$中的系数来观察$y=\mathbf{q}^T\mathbf{s}$的分布如何变化。这里的基本思想是，既然两个独立随机变量之和分布的高斯性都比原始变量的更强，那么$y=\mathbf{q}^T\mathbf{s}$应该比任意一个$s_i$的高斯性更强，除非y刚好就是$s_i$中的一个，只有在该情况下y的高斯性才最弱（注意，该结论只有在假定所有$s_i$具有相同分布的情况下才严格成立）。这是显然$\mathbf{q}$中只有一个元素$q_i$为非零值。

实际情况下我们并不知道$\mathbf{q}$的值，但也无须知道，因为根据定义$\mathbf{b}^T\mathbf{x}=\mathbf{q}^T\mathbf{s}$，可以只让$\mathbf{b}$变化并观察$\mathbf{b}^T\mathbf{x}$的分布变化情况。因此可以直接把变量$\mathbf{b}$用于极大化$\mathbf{b}^T\mathbf{x}$的非高斯性，这样的向量对应于$\mathbf{q}=\mathbf{A}^T\mathbf{b}$只有一个非零元素的情形，从而意味着$ y=\mathbf{b}^T\mathbf{x}=\mathbf{q}^T\mathbf{s}$正好等同于独立成分中的一个。也就是说通过极大化$\mathbf{b}^T\mathbf{x}$的非高斯性，就能给出其中一个独立成分。



\subsection{用峭度来度量非高斯性}
为了在ICA估计中使用非高斯性，我们必须对一个随机变量的非高斯性定义一个量化的指标，我们可以采用峭度这一指标，峭度是随机变量的四阶累积量的另一种叫法，y的峭度kurt(y)可定义为
\begin{equation}
kurt(y)=E\{y^4\}-3(E\{y^2\})^2
\end{equation}
注意上式中的所有随机变量都假定是零均值的。对于一般的情况，定义会更复杂些。为了简化问题，我们还可以进一步假定$y$已经被标准化过，其方差等于1：$E\{y^2\}=1$。这样峭度定义公式的右边简化为$E{y_4}-3$。这说明，峭度可以看作四阶矩的一种规范化形式。对于高斯分布的变量$y$,其四阶矩等于$3(E\{y^2\})$，因此高斯变量的峭度为零。对于大部分（但并不是所有）的非高斯随机变量，峭度为非零值。

\textbf{基于峭度的梯度算法}：在实践中，为了极大化峭度的绝对值，我们可以从某个向量$\mathbf{w}$开始，依据可用的样本值$\mathbf{z}(1),\cdots,\mathbf{z}(T)$,计算出使得$y=\mathbf{w}^T\mathbf{z}$的峭度绝对值增大最快的方向，然后将向量$w$转到该方向。这种思路可以用梯度法来实现。

$\mathbf{w}^T\mathbf{z}$的峭度绝对值的梯度可以用下式计算得到：
\begin{equation}
\frac{\partial| \mathbf{w}^T\mathbf{z} |}{\partial \mathbf{w}}
=4sign( kurt( \mathbf{w}^T\mathbf{z} ) ) [ E\{ \mathbf{z}(\mathbf{w}^T\mathbf{z})^3 \} - 3 \mathbf{w} \lVert \mathbf{w} \rVert^2 ]  \label{equ:wzw}
\end{equation}
对于白化过的数据，有$E\{ (\mathbf{w}^T\mathbf{z})^2 \}= \Vert \mathbf{w} \rVert^2$。由于我们是在单位球$\lVert \mathbf{w} \rVert^2=1$上进行优化，梯度法必须进行一定的补充，即在每一步运算后将$\mathbf{w}$投影到单位球上，实际上只要简单地将$\mathbf{w}$除以其范数即可。

因此我们得到下面的梯度算法：
\begin{align}
\Delta\mathbf{w} \propto sign( kurt( \mathbf{w}^T\mathbf{z} ) ) E\{ \mathbf{z}( \mathbf{w}^T\mathbf{z} )^3 \} \\
\mathbf{w}\leftarrow \mathbf{w}/\lVert\mathbf{w}\rVert
\end{align}

\textbf{基于峭度的快速不动点算法}：虽然基于峭度的梯度算法，理论上可以有效收敛，但是收敛慢，且如果速度选择不当，收敛性甚至会被破坏，所以需要一种学习速度和可靠性上都有保障的算法，不动点迭代法就是一种这样的方法。

关于不动点迭代，可以参考附录\ref{apx:2}。为了得到梯度算法的不动点迭代，我们注意到在梯度算法的一个稳定点处，梯度必须指向$\mathbf{w}$的方向，也就是说梯度必须等于一个常量标量和$\mathbf{w}$的乘积，只有在这种情况下，将梯度与$\mathbf{w}$相加才不改变其方向，且算法在此处收敛。该结论可以用拉格朗日乘子法予以严格证明。令式(\ref{equ:wzw})中的梯度与$\mathbf{w}$相等，可以得到：
\begin{equation}
\mathbf{w} \propto [ E\{ \mathbf{z}(\mathbf{w}^T\mathbf{z})^3 \} - 3 \mathbf{w} \lVert \mathbf{w} \rVert^2 ]
\end{equation}
我们可以每次计算右边的项，将其赋给$\mathbf{w}$作为新值,并且每次迭代后$\mathbf{w}$都除以其范数以满足$\lVert \mathbf{w} \rVert =1 $,即可得到：
\begin{equation}
\mathbf{w} \leftarrow E\{ \mathbf{z}(\mathbf{w}^T\mathbf{z})^3 \} - 3 \mathbf{w} \label{equ:bdd}
\end{equation}
公式(\ref{equ:bdd})即是一个不动点迭代公式。